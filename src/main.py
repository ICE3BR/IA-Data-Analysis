import io
import sys

import pandas as pd
import streamlit as st
from langchain_ollama import (
    OllamaLLM,  # Importa a classe OllamaLLM do pacote langchain-ollama
)
from pandasai import SmartDataframe

# Configura√ß√µes iniciais da interface Streamlit
st.title("üöÄ Data Analysis with PandasAI")


# Fun√ß√£o para carregar e ajustar os dados do CSV
@st.cache_data
def load_data(file):
    """
    Carrega e ajusta os dados do arquivo CSV.

    Args:
        file (UploadedFile): Arquivo CSV carregado pelo usu√°rio.

    Returns:
        pd.DataFrame: DataFrame com os dados carregados e colunas ajustadas.
    """
    data = pd.read_csv(file, encoding="utf-8")
    data.columns = data.columns.astype(
        str
    ).str.strip()  # Remove espa√ßos extras nos nomes das colunas
    return data


# Fun√ß√£o para exibir os primeiros registros do DataFrame
def display_data(data):
    """
    Exibe os primeiros registros do DataFrame.

    Args:
        data (pd.DataFrame): DataFrame com os dados carregados.
    """
    st.write("üìä **Visualizando os primeiros dados:**")
    st.write(data.head(3))  # Mostra as primeiras 3 linhas do DataFrame


# Fun√ß√£o para processar o prompt do usu√°rio e retornar a resposta
def process_prompt(df, prompt):
    """
    Processa o prompt do usu√°rio usando o SmartDataframe.

    Args:
        df (SmartDataframe): DataFrame inteligente configurado com o modelo LLM.
        prompt (str): Comando ou pergunta do usu√°rio.

    Returns:
        tuple: Resposta gerada pelo modelo e texto capturado do terminal.
    """
    with st.spinner("‚è≥ Gerando resposta..."):
        try:
            # Captura a sa√≠da padr√£o para redirecionar para uma vari√°vel
            captured_output = io.StringIO()
            sys.stdout = captured_output

            # Chama o m√©todo chat do SmartDataframe
            response = df.chat(prompt)

            # Restaura a sa√≠da padr√£o
            sys.stdout = sys.__stdout__

            # Obt√©m o texto capturado
            output_text = captured_output.getvalue().strip()
            return response, output_text
        except Exception as e:
            # Restaura a sa√≠da padr√£o caso ocorra erro
            sys.stdout = sys.__stdout__
            st.error(f"‚ùå Erro ao processar o prompt: {e}")
            st.write("üîç Verifique os nomes das colunas:", df.dataframe.columns)
            return None, None


# Upload de arquivo CSV
uploader_file = st.file_uploader("‚¨ÜÔ∏è Upload um arquivo CSV", type=["csv"])

# Verifica se um arquivo foi carregado
if uploader_file is not None:
    try:
        # Carrega e exibe os dados
        data = load_data(uploader_file)
        display_data(data)

        # Configura o modelo LLM e cria o SmartDataframe
        llm = OllamaLLM(model="deepseek-r1:8b")  # Use a classe OllamaLLM
        df = SmartDataframe(data, config={"llm": llm, "cache": None})
    except Exception as e:
        # Exibe mensagem de erro caso falhe ao carregar o arquivo
        st.error(f"‚ùå Erro ao carregar o arquivo: {e}")
        st.stop()

# Entrada de prompt do usu√°rio com exemplo
prompt = st.text_area(
    "üìù Digite seu comando:",
    value="Com apenas os dados existentes. Liste os 5 pa√≠ses com a menor popula√ß√£o em ordem crescente. Retorne uma tabela formatada.",
)

# Bot√£o para gerar resposta
if st.button("üöÄ Gerar Resposta"):
    # Verifica se o prompt n√£o est√° vazio
    if prompt.strip():
        # Processa o prompt e obt√©m a resposta e o texto capturado
        response, output_text = process_prompt(df, prompt)

        # Placeholder para exibir a resposta
        response_placeholder = st.empty()

        # Verifica se h√° uma resposta
        if response is not None:
            # Se a resposta for um DataFrame, exibe a tabela formatada
            if isinstance(response, pd.DataFrame):
                response_placeholder.write("üìä **Tabela Resultante:**")
                response_placeholder.dataframe(response)
            # Se a resposta for um caminho de imagem, exibe o gr√°fico
            elif isinstance(response, str) and response.endswith(".png"):
                response_placeholder.image(
                    response,
                    caption="üìä Gr√°fico gerado pelo PandasAI",
                    use_container_width=True,
                )
            else:
                # Caso contr√°rio, exibe a resposta como texto
                response_placeholder.write(response)

        # Exibe o texto capturado do terminal
        if output_text:
            st.text(output_text)
    else:
        # Exibe aviso se o prompt estiver vazio
        st.warning("‚ö†Ô∏è O comando n√£o pode estar vazio!")
